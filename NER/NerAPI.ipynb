{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "scf1DzF-ChGq",
      "metadata": {
        "id": "scf1DzF-ChGq"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate bitsandbytes scipy -q --upgrade\n",
        "!pip install json_repair -q\n",
        "!pip install fastapi uvicorn pyngrok nest-asyncio python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "umifKN2b8_5-",
      "metadata": {
        "id": "umifKN2b8_5-"
      },
      "outputs": [],
      "source": [
        "# upload the .env file and NER.py file\n",
        "from google.colab import files \n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf39de4",
      "metadata": {
        "id": "aaf39de4",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Dict, List, Optional, Any\n",
        "import logging\n",
        "import time\n",
        "import datetime\n",
        "import nest_asyncio\n",
        "import threading\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import re , string, warnings , torch , string, json_repair , json,os\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,AutoModelForTokenClassification\n",
        "from collections import defaultdict\n",
        "from pydantic import BaseModel, Field, validator , root_validator, model_validator\n",
        "from typing import Dict, List, Tuple, Set, Optional, Any , Dict\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re , string, warnings , torch , string, json_repair , json\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,AutoModelForTokenClassification\n",
        "from collections import defaultdict\n",
        "from pydantic import BaseModel, Field, validator , root_validator, model_validator\n",
        "from typing import Dict, List, Tuple, Set, Optional, Any , Dict\n",
        "from pprint import pprint\n",
        "\n",
        "from NER import NERExtractor , NEREntities\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "auth_token = os.environ.get(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "ner_extractor = NERExtractor(quantized_8=True)\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"Named Entity Recognition API\",\n",
        "    description=\"A high-performance NER service using Qwen2.5-7B-Instruct\",\n",
        "    version=\"1.0.0\"\n",
        ")\n",
        "\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "class NERRequest(BaseModel):\n",
        "    text: str = Field(..., min_length=1, max_length=10000, description=\"Text to analyze for named entities\")\n",
        "\n",
        "class NERResponse(BaseModel):\n",
        "    entities: Dict[str, List[str]]\n",
        "    processing_time: float = Field(..., description=\"Processing time in seconds\")\n",
        "\n",
        "class HealthResponse(BaseModel):\n",
        "    status: str\n",
        "    model_loaded: bool\n",
        "    timestamp: str\n",
        "\n",
        "@app.get(\"/\", response_model=Dict[str, str])\n",
        "async def root():\n",
        "    \"\"\"Root endpoint with API information\"\"\"\n",
        "    return {\n",
        "        \"message\": \"Named Entity Recognition API\",\n",
        "        \"version\": \"1.0.0\",\n",
        "        \"docs\": \"/docs\",\n",
        "        \"health\": \"/NERhealth\"\n",
        "    }\n",
        "\n",
        "@app.get(\"/NER/health\", response_model=HealthResponse)\n",
        "async def health_check():\n",
        "    \"\"\"Health check endpoint\"\"\"\n",
        "    return HealthResponse(\n",
        "        status=\"healthy\" if ner_extractor is not None else \"unhealthy\",\n",
        "        model_loaded=ner_extractor is not None,\n",
        "        timestamp=datetime.now().isoformat()\n",
        "    )\n",
        "\n",
        "@app.post(\"/NER/extract\", response_model=NERResponse)\n",
        "async def extract_entities(request: NERRequest):\n",
        "    \"\"\"Extract named entities from text\"\"\"\n",
        "    if ner_extractor is None:\n",
        "        raise HTTPException(\n",
        "            status_code=503,\n",
        "            detail=\"NER model is not loaded. Please try again later.\"\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        entities_raw = ner_extractor.ner_predict(request.text)\n",
        "\n",
        "        if isinstance(entities_raw, str):\n",
        "            entities = json.loads(entities_raw)\n",
        "        else:\n",
        "            entities = entities_raw\n",
        "        processing_time = time.time() - start_time\n",
        "\n",
        "        return NERResponse(\n",
        "            entities=entities,\n",
        "            processing_time=round(processing_time, 3),\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing NER request: {str(e)}\")\n",
        "        raise HTTPException(\n",
        "            status_code=500,\n",
        "            detail=f\"Error processing text: {str(e)}\"\n",
        "        )\n",
        "\n",
        "@app.get(\"/NER/info\")\n",
        "async def get_ner_model_info():\n",
        "    \"\"\"Get information about the loaded model\"\"\"\n",
        "    if ner_extractor is None:\n",
        "        raise HTTPException(\n",
        "            status_code=503,\n",
        "            detail=\"NER model is not loaded\"\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"model_name\": \"Qwen/Qwen2.5-7B-Instruct\",\n",
        "        \"entity_types\": list(NEREntities.__fields__.keys())\n",
        "    }\n",
        "\n",
        "def run_server():\n",
        "    \"\"\"Run the FastAPI server\"\"\"\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8002, log_level=\"info\")\n",
        "\n",
        "def start_server_with_ngrok():\n",
        "    \"\"\"Start server with ngrok tunnel for Colab\"\"\"\n",
        "    auth_token = os.environ.get(\"NGROK_AUTH_TOKEN\")\n",
        "    ngrok.set_auth_token(auth_token)\n",
        "\n",
        "    server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "    server_thread.start()\n",
        "\n",
        "    time.sleep(3)\n",
        "\n",
        "\n",
        "    public_url = ngrok.connect(8002)\n",
        "\n",
        "    print(\"FastAPI Server Started!\")\n",
        "    print(f\"Public URL: {public_url}\")\n",
        "    print(f\"API Documentation: {public_url}/docs\")\n",
        "    print(f\"Health Check: {public_url}/NER/health\")\n",
        "    print(f\"Extract Entities: {public_url}/NER/extract\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    colab = True\n",
        "    if colab :\n",
        "      public_url = start_server_with_ngrok()\n",
        "\n",
        "      try:\n",
        "          while True:\n",
        "              time.sleep(1)\n",
        "      except KeyboardInterrupt:\n",
        "          print(\"\\nServer stopped\")\n",
        "          ngrok.disconnect(public_url)\n",
        "    else :\n",
        "      run_server()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
